{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takahashikoji/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "id_test = test['id'].values\n",
    "target_train = train['target'].values\n",
    "\n",
    "train = train.drop(['target','id'], axis = 1)\n",
    "test = test.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(col_to_drop, axis=1)  \n",
    "test = test.drop(col_to_drop, axis=1)  \n",
    "\n",
    "\n",
    "train = train.replace(-1, np.nan)\n",
    "test = test.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 198) (892816, 198)\n"
     ]
    }
   ],
   "source": [
    "cat_features = [a for a in train.columns if a.endswith('cat')]\n",
    "\n",
    "for column in cat_features:\n",
    "\ttemp = pd.get_dummies(pd.Series(train[column]))\n",
    "\ttrain = pd.concat([train,temp],axis=1)\n",
    "\ttrain = train.drop([column],axis=1)\n",
    "    \n",
    "for column in cat_features:\n",
    "\ttemp = pd.get_dummies(pd.Series(test[column]))\n",
    "\ttest = pd.concat([test,temp],axis=1)\n",
    "\ttest = test.drop([column],axis=1)\n",
    "\n",
    "\n",
    "print(train.values.shape, test.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2016).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "#                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "#                cross_score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "#                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=3, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LightGBM params\n",
    "#lgb_params = {}\n",
    "#lgb_params['learning_rate'] = 0.02\n",
    "#lgb_params['n_estimators'] = 650\n",
    "#lgb_params['max_bin'] = 10\n",
    "#lgb_params['subsample'] = 0.8\n",
    "#lgb_params['subsample_freq'] = 10\n",
    "#lgb_params['colsample_bytree'] = 0.8   \n",
    "#lgb_params['min_child_samples'] = 500\n",
    "#lgb_params['seed'] = 99\n",
    "\n",
    "\n",
    "#lgb_params2 = {}\n",
    "#lgb_params2['n_estimators'] = 1090\n",
    "#lgb_params2['learning_rate'] = 0.02\n",
    "#lgb_params2['colsample_bytree'] = 0.3   \n",
    "#lgb_params2['subsample'] = 0.7\n",
    "#lgb_params2['subsample_freq'] = 2\n",
    "#lgb_params2['num_leaves'] = 16\n",
    "#lgb_params2['seed'] = 99\n",
    "\n",
    "\n",
    "#lgb_params3 = {}\n",
    "#lgb_params3['n_estimators'] = 1100\n",
    "#lgb_params3['max_depth'] = 4\n",
    "#lgb_params3['learning_rate'] = 0.02\n",
    "#lgb_params3['seed'] = 99\n",
    "\n",
    "\n",
    "# RandomForest params\n",
    "rf_params = {}\n",
    "rf_params['n_estimators'] = 200\n",
    "rf_params['max_depth'] = 6\n",
    "rf_params['min_samples_split'] = 70\n",
    "rf_params['min_samples_leaf'] = 30\n",
    "\n",
    "\n",
    "# ExtraTrees params\n",
    "#et_params = {}\n",
    "#et_params['n_estimators'] = 155\n",
    "#et_params['max_features'] = 0.3\n",
    "#et_params['max_depth'] = 6\n",
    "#et_params['min_samples_split'] = 40\n",
    "#et_params['min_samples_leaf'] = 18\n",
    "\n",
    "\n",
    "# XGBoost params\n",
    "xgb_params = {}\n",
    "xgb_params['objective'] = 'binary:logistic'\n",
    "xgb_params['learning_rate'] = 0.04\n",
    "xgb_params['n_estimators'] = 490\n",
    "xgb_params['max_depth'] = 4\n",
    "xgb_params['subsample'] = 0.9\n",
    "xgb_params['colsample_bytree'] = 0.9  \n",
    "xgb_params['min_child_weight'] = 10\n",
    "\n",
    "\n",
    "# CatBoost params\n",
    "#cat_params = {}\n",
    "#cat_params['iterations'] = 900\n",
    "#cat_params['depth'] = 8\n",
    "#cat_params['rsm'] = 0.95\n",
    "#cat_params['learning_rate'] = 0.03\n",
    "#cat_params['l2_leaf_reg'] = 3.5  \n",
    "#cat_params['border_count'] = 8\n",
    "#cat_params['gradient_iterations'] = 4\n",
    "\n",
    "\n",
    "# Regularized Greedy Forest params\n",
    "#rgf_params = {}\n",
    "#rgf_params['max_leaf'] = 2000\n",
    "#rgf_params['learning_rate'] = 0.5\n",
    "#rgf_params['algorithm'] = \"RGF_Sib\"\n",
    "#rgf_params['test_interval'] = 100\n",
    "#rgf_params['min_samples_leaf'] = 3 \n",
    "#rgf_params['reg_depth'] = 1.0\n",
    "#rgf_params['l2'] = 0.5  \n",
    "#rgf_params['sl2'] = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lgb_model = LGBMClassifier(**lgb_params)\n",
    "\n",
    "#lgb_model2 = LGBMClassifier(**lgb_params2)\n",
    "\n",
    "#lgb_model3 = LGBMClassifier(**lgb_params3)\n",
    "\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "\n",
    "#et_model = ExtraTreesClassifier(**et_params)\n",
    "        \n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "\n",
    "#cat_model = CatBoostClassifier(**cat_params)\n",
    "\n",
    "#rgf_model = RGFClassifier(**rgf_params) \n",
    "\n",
    "#gb_model = GradientBoostingClassifier(max_depth=5)\n",
    "\n",
    "#ada_model = AdaBoostClassifier()\n",
    "\n",
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.replace(np.nan,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps_ind_01        False\n",
       "ps_ind_03        False\n",
       "ps_ind_06_bin    False\n",
       "ps_ind_07_bin    False\n",
       "ps_ind_08_bin    False\n",
       "ps_ind_09_bin    False\n",
       "ps_ind_10_bin    False\n",
       "ps_ind_11_bin    False\n",
       "ps_ind_12_bin    False\n",
       "ps_ind_13_bin    False\n",
       "ps_ind_14        False\n",
       "ps_ind_15        False\n",
       "ps_ind_16_bin    False\n",
       "ps_ind_17_bin    False\n",
       "ps_ind_18_bin    False\n",
       "ps_reg_01        False\n",
       "ps_reg_02        False\n",
       "ps_reg_03        False\n",
       "ps_car_11        False\n",
       "ps_car_12        False\n",
       "ps_car_13        False\n",
       "ps_car_14        False\n",
       "ps_car_15        False\n",
       "1.0              False\n",
       "2.0              False\n",
       "3.0              False\n",
       "4.0              False\n",
       "0.0              False\n",
       "1.0              False\n",
       "0.0              False\n",
       "                 ...  \n",
       "75               False\n",
       "76               False\n",
       "77               False\n",
       "78               False\n",
       "79               False\n",
       "80               False\n",
       "81               False\n",
       "82               False\n",
       "83               False\n",
       "84               False\n",
       "85               False\n",
       "86               False\n",
       "87               False\n",
       "88               False\n",
       "89               False\n",
       "90               False\n",
       "91               False\n",
       "92               False\n",
       "93               False\n",
       "94               False\n",
       "95               False\n",
       "96               False\n",
       "97               False\n",
       "98               False\n",
       "99               False\n",
       "100              False\n",
       "101              False\n",
       "102              False\n",
       "103              False\n",
       "104              False\n",
       "Length: 198, dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.replace(np.nan, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit RandomForestClassifier fold 1\n",
      "Fit RandomForestClassifier fold 2\n",
      "Fit RandomForestClassifier fold 3\n",
      "Fit XGBClassifier fold 1\n",
      "Fit XGBClassifier fold 2\n",
      "Fit XGBClassifier fold 3\n",
      "Stacker score: 0.64012\n"
     ]
    }
   ],
   "source": [
    "stack = Ensemble(n_splits=3,\n",
    "        stacker = log_model,\n",
    "        base_models = (rf_model ,xgb_model))      \n",
    "        \n",
    "y_pred = stack.fit_predict(train, target_train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_pred\n",
    "sub.to_csv('stacked_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
